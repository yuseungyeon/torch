{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2310813d250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suitable-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complete-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-bottom",
   "metadata": {},
   "source": [
    "### Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fallen-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad = True)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "durable-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1, requires_grad = True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-baghdad",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "progressive-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-quality",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "allied-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bottom-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confidential-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.],\n",
      "        [-2.],\n",
      "        [-3.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "catholic-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [4.],\n",
      "        [9.]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((hypothesis-y_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "periodic-survival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-exercise",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "approximate-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W,b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "improving-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dominican-pension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0933], requires_grad=True)\n",
      "tensor([0.0400], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "defensive-portuguese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1333],\n",
      "        [0.2267],\n",
      "        [0.3200]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6927, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-heating",
   "metadata": {},
   "source": [
    "### Training with Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mighty-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
      "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
      "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
      "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
      "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
      "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
      "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
      "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
      "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
      "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
      "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    hypothesis = x_train * W + b\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}\".format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-ending",
   "metadata": {},
   "source": [
    "## High-level Implementation with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ordinary-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "handmade-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x): # 어떻게 입력값에서 출력값을 계산하는지\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "genetic-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-casting",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amino-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "processed-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0739],\n",
      "        [0.5891],\n",
      "        [1.1044]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-population",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "paperback-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0739],\n",
      "        [0.5891],\n",
      "        [1.1044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vulnerable-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = F.mse_loss(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "traditional-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1471, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-wagner",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "protecting-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "primary-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-breath",
   "metadata": {},
   "source": [
    "### Training with Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "blessed-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.634, b: -0.388, Cost: 1.698280\n",
      "Epoch  100/1000 W: 1.066, b: -0.150, Cost: 0.003224\n",
      "Epoch  200/1000 W: 1.052, b: -0.118, Cost: 0.001992\n",
      "Epoch  300/1000 W: 1.041, b: -0.092, Cost: 0.001231\n",
      "Epoch  400/1000 W: 1.032, b: -0.073, Cost: 0.000761\n",
      "Epoch  500/1000 W: 1.025, b: -0.057, Cost: 0.000470\n",
      "Epoch  600/1000 W: 1.020, b: -0.045, Cost: 0.000290\n",
      "Epoch  700/1000 W: 1.016, b: -0.035, Cost: 0.000179\n",
      "Epoch  800/1000 W: 1.012, b: -0.028, Cost: 0.000111\n",
      "Epoch  900/1000 W: 1.010, b: -0.022, Cost: 0.000069\n",
      "Epoch 1000/1000 W: 1.008, b: -0.017, Cost: 0.000042\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[1],[2],[3]])\n",
    "\n",
    "mode = LinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print(\"Epoch {:4d}/{} W: {:.3f}, b: {:.3f}, Cost: {:.6f}\".format(epoch, nb_epochs, W, b, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
